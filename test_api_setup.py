"""
æµ‹è¯•é˜¿é‡Œäº‘APIé…ç½®å’ŒåŸºæœ¬åŠŸèƒ½
"""
import os
from dotenv import load_dotenv

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()

def test_env_variables():
    """æµ‹è¯•ç¯å¢ƒå˜é‡é…ç½®"""
    print("=" * 50)
    print("æµ‹è¯•ç¯å¢ƒå˜é‡é…ç½®")
    print("=" * 50)
    
    api_key = os.getenv("DASHSCOPE_API_KEY")
    if api_key:
        print(f"âœ“ DASHSCOPE_API_KEY: {api_key[:10]}...{api_key[-4:]}")
    else:
        print("âœ— DASHSCOPE_API_KEY æœªè®¾ç½®")
        return False
    
    embedding_model = os.getenv("EMBEDDING_MODEL", "text-embedding-v3")
    print(f"âœ“ EMBEDDING_MODEL: {embedding_model}")
    
    llm_model = os.getenv("LLM_MODEL", "qwen-plus")
    print(f"âœ“ LLM_MODEL: {llm_model}")
    
    threshold = os.getenv("RELEVANCE_THRESHOLD", "0.5")
    print(f"âœ“ RELEVANCE_THRESHOLD: {threshold}")
    
    return True

def test_embedding():
    """æµ‹è¯•EmbeddingåŠŸèƒ½"""
    print("\n" + "=" * 50)
    print("æµ‹è¯•EmbeddingåŠŸèƒ½")
    print("=" * 50)
    
    try:
        from langchain_openai import OpenAIEmbeddings
        from config import DASHSCOPE_API_KEY, DASHSCOPE_BASE_URL, EMBEDDING_MODEL
        
        embeddings = OpenAIEmbeddings(
            model=EMBEDDING_MODEL,
            openai_api_key=DASHSCOPE_API_KEY,
            openai_api_base=DASHSCOPE_BASE_URL
        )
        
        # æµ‹è¯•ç”Ÿæˆembedding
        test_text = "è¿™æ˜¯ä¸€ä¸ªæµ‹è¯•æ–‡æœ¬"
        print(f"æµ‹è¯•æ–‡æœ¬: {test_text}")
        
        result = embeddings.embed_query(test_text)
        print(f"âœ“ Embeddingç”ŸæˆæˆåŠŸ")
        print(f"  ç»´åº¦: {len(result)}")
        print(f"  å‰5ä¸ªå€¼: {result[:5]}")
        
        return True
        
    except Exception as e:
        print(f"âœ— Embeddingæµ‹è¯•å¤±è´¥: {e}")
        return False

def test_llm():
    """æµ‹è¯•LLMåŠŸèƒ½"""
    print("\n" + "=" * 50)
    print("æµ‹è¯•LLMåŠŸèƒ½")
    print("=" * 50)
    
    try:
        from langchain_openai import ChatOpenAI
        from config import (
            DASHSCOPE_API_KEY, DASHSCOPE_BASE_URL, LLM_MODEL,
            LLM_TEMPERATURE, LLM_TOP_P, LLM_MAX_TOKENS
        )
        
        llm = ChatOpenAI(
            model=LLM_MODEL,
            openai_api_key=DASHSCOPE_API_KEY,
            openai_api_base=DASHSCOPE_BASE_URL,
            temperature=LLM_TEMPERATURE,
            top_p=LLM_TOP_P,
            max_tokens=LLM_MAX_TOKENS
        )
        
        # æµ‹è¯•ç”Ÿæˆå›ç­”
        test_prompt = "è¯·ç”¨ä¸€å¥è¯ä»‹ç»ä½ è‡ªå·±ã€‚"
        print(f"æµ‹è¯•æç¤º: {test_prompt}")
        
        response = llm.invoke(test_prompt)
        print(f"âœ“ LLMè°ƒç”¨æˆåŠŸ")
        print(f"  å›ç­”: {response.content}")
        
        return True
        
    except Exception as e:
        print(f"âœ— LLMæµ‹è¯•å¤±è´¥: {e}")
        return False

def test_document_splitter():
    """æµ‹è¯•æ–‡æ¡£åˆ‡å‰²å™¨"""
    print("\n" + "=" * 50)
    print("æµ‹è¯•æ–‡æ¡£åˆ‡å‰²å™¨")
    print("=" * 50)
    
    try:
        from document_splitter import create_hr_splitter
        
        splitter = create_hr_splitter()
        
        # æµ‹è¯•æ–‡æœ¬
        test_text = """ä¸€ã€è–ªèµ„ç®¡ç†åˆ¶åº¦

1. è–ªèµ„æ„æˆ
å‘˜å·¥è–ªèµ„ç”±åŸºæœ¬å·¥èµ„ã€ç»©æ•ˆå¥–é‡‘ã€æ´¥è´´è¡¥è´´ç­‰ç»„æˆã€‚

2. è–ªèµ„å‘æ”¾
æ¯æœˆ15æ—¥å‘æ”¾ä¸Šæœˆè–ªèµ„ã€‚

äºŒã€è€ƒå‹¤ç®¡ç†åˆ¶åº¦

1. æ‰“å¡è¦æ±‚
å‘˜å·¥éœ€æ¯æ—¥ä¸Šä¸‹ç­æ‰“å¡ã€‚

2. è¯·å‡æµç¨‹
è¯·å‡éœ€æå‰ç”³è¯·ï¼Œç»ä¸»ç®¡æ‰¹å‡†åç”Ÿæ•ˆã€‚"""
        
        print(f"æµ‹è¯•æ–‡æœ¬é•¿åº¦: {len(test_text)} å­—ç¬¦")
        
        chunks = splitter.split_text(test_text)
        print(f"âœ“ æ–‡æ¡£åˆ‡å‰²æˆåŠŸ")
        print(f"  åˆ‡å‰²å—æ•°: {len(chunks)}")
        for i, chunk in enumerate(chunks, 1):
            print(f"\n  å— {i} ({len(chunk)} å­—ç¬¦):")
            print(f"  {chunk[:100]}...")
        
        return True
        
    except Exception as e:
        print(f"âœ— æ–‡æ¡£åˆ‡å‰²å™¨æµ‹è¯•å¤±è´¥: {e}")
        return False

def test_relevance_evaluator():
    """æµ‹è¯•ç›¸å…³æ€§è¯„ä¼°å™¨"""
    print("\n" + "=" * 50)
    print("æµ‹è¯•ç›¸å…³æ€§è¯„ä¼°å™¨")
    print("=" * 50)
    
    try:
        from relevance_evaluator import create_relevance_evaluator
        from langchain.schema import Document
        
        evaluator = create_relevance_evaluator()
        
        # åˆ›å»ºæµ‹è¯•æ–‡æ¡£
        docs = [
            Document(page_content="è–ªèµ„å‘æ”¾æ—¶é—´", metadata={'score': 0.8}),
            Document(page_content="è€ƒå‹¤ç®¡ç†åˆ¶åº¦", metadata={'score': 0.6}),
            Document(page_content="åŸ¹è®­å‘å±•è®¡åˆ’", metadata={'score': 0.3}),
        ]
        
        query = "è–ªèµ„ä»€ä¹ˆæ—¶å€™å‘æ”¾ï¼Ÿ"
        print(f"æµ‹è¯•æŸ¥è¯¢: {query}")
        
        result = evaluator.evaluate(query, docs)
        print(f"âœ“ ç›¸å…³æ€§è¯„ä¼°æˆåŠŸ")
        print(f"  æ˜¯å¦ç›¸å…³: {result['is_relevant']}")
        print(f"  æœ€é«˜åˆ†æ•°: {result['max_score']:.3f}")
        print(f"  å¹³å‡åˆ†æ•°: {result['avg_score']:.3f}")
        print(f"  ç›¸å…³æ–‡æ¡£æ•°: {result['relevant_count']}/{len(docs)}")
        
        return True
        
    except Exception as e:
        print(f"âœ— ç›¸å…³æ€§è¯„ä¼°å™¨æµ‹è¯•å¤±è´¥: {e}")
        return False

def main():
    """è¿è¡Œæ‰€æœ‰æµ‹è¯•"""
    print("\n" + "=" * 50)
    print("é˜¿é‡Œäº‘APIé…ç½®å’ŒåŠŸèƒ½æµ‹è¯•")
    print("=" * 50 + "\n")
    
    results = []
    
    # 1. æµ‹è¯•ç¯å¢ƒå˜é‡
    results.append(("ç¯å¢ƒå˜é‡é…ç½®", test_env_variables()))
    
    # 2. æµ‹è¯•Embedding
    results.append(("EmbeddingåŠŸèƒ½", test_embedding()))
    
    # 3. æµ‹è¯•LLM
    results.append(("LLMåŠŸèƒ½", test_llm()))
    
    # 4. æµ‹è¯•æ–‡æ¡£åˆ‡å‰²å™¨
    results.append(("æ–‡æ¡£åˆ‡å‰²å™¨", test_document_splitter()))
    
    # 5. æµ‹è¯•ç›¸å…³æ€§è¯„ä¼°å™¨
    results.append(("ç›¸å…³æ€§è¯„ä¼°å™¨", test_relevance_evaluator()))
    
    # æ±‡æ€»ç»“æœ
    print("\n" + "=" * 50)
    print("æµ‹è¯•ç»“æœæ±‡æ€»")
    print("=" * 50)
    
    for name, result in results:
        status = "âœ“ é€šè¿‡" if result else "âœ— å¤±è´¥"
        print(f"{name}: {status}")
    
    total = len(results)
    passed = sum(1 for _, r in results if r)
    print(f"\næ€»è®¡: {passed}/{total} é€šè¿‡")
    
    if passed == total:
        print("\nğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼ç³»ç»Ÿé…ç½®æ­£ç¡®ã€‚")
    else:
        print("\nâš ï¸ éƒ¨åˆ†æµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥é…ç½®ã€‚")

if __name__ == "__main__":
    main()
