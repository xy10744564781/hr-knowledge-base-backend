"""
å›ç­”ç”Ÿæˆé“¾

åŸºäºæ£€ç´¢ç»“æœå’Œç”¨æˆ·ä¸Šä¸‹æ–‡ç”Ÿæˆä¸ªæ€§åŒ–å›ç­”
"""

from typing import Dict, Any, Optional, List

# å°è¯•å¯¼å…¥ LangChain çš„ ChatOpenAI
try:
    from langchain_openai import ChatOpenAI
except ImportError:
    try:
        from langchain.llms import OpenAI as ChatOpenAI
    except ImportError:
        # å¦‚æœéƒ½å¤±è´¥ï¼Œä½¿ç”¨ç°æœ‰çš„ llm_agent ä½œä¸ºé™çº§
        from llm_agent import get_hr_agent
        ChatOpenAI = None

from .base_chain import BaseKnowledgeChain
from .models import UserContext, ChainInput, DocumentResult
from config import DASHSCOPE_API_KEY, DASHSCOPE_BASE_URL, LLM_MODEL


class AnswerGenerationChain(BaseKnowledgeChain):
    """å›ç­”ç”Ÿæˆé“¾"""
    
    def __init__(self, **kwargs):
        super().__init__(chain_name="answer_generation", **kwargs)
        self.llm = self._initialize_llm()
        self.prompt_builder = PromptBuilder()
    
    def _initialize_llm(self) -> ChatOpenAI:
        """åˆå§‹åŒ–LLM"""
        try:
            return ChatOpenAI(
                model=LLM_MODEL,
                openai_api_key=DASHSCOPE_API_KEY,
                openai_api_base=DASHSCOPE_BASE_URL,
                temperature=0.3,  # é€‚ä¸­çš„æ¸©åº¦ï¼Œä¿æŒä¸€è‡´æ€§ä½†å…è®¸ä¸€å®šåˆ›é€ æ€§
                max_tokens=1500
            )
        except Exception as e:
            self.logger.error(f"LLMåˆå§‹åŒ–å¤±è´¥: {str(e)}")
            return None
    
    def _execute_chain(
        self, 
        inputs: Dict[str, Any], 
        run_manager: Optional[Any] = None
    ) -> Dict[str, Any]:
        """æ‰§è¡Œå›ç­”ç”Ÿæˆ"""
        chain_input: ChainInput = inputs["input_data"]
        user_context: UserContext = inputs.get("user_context")
        documents: List[DocumentResult] = inputs.get("documents", [])
        intent_analysis = inputs.get("intent_analysis")  # è·å–æ„å›¾åˆ†æç»“æœ
        retrieval_strategy = inputs.get("retrieval_strategy")  # è·å–æ£€ç´¢ç­–ç•¥
        
        if not user_context:
            raise ValueError("ç¼ºå°‘ç”¨æˆ·ä¸Šä¸‹æ–‡ä¿¡æ¯")
        
        query = chain_input.query
        
        self.logger.info(
            f"ç”Ÿæˆå›ç­”: ç”¨æˆ·={user_context.username}, "
            f"æ–‡æ¡£æ•°={len(documents)}, æŸ¥è¯¢='{query[:50]}...'"
        )
        
        try:
            if not self.llm:
                # é™çº§åˆ°æ¨¡æ¿å›ç­”
                return self._generate_template_answer(query, documents, user_context)
            
            # éªŒè¯æ–‡æ¡£ç›¸å…³æ€§
            if documents and intent_analysis:
                relevant_docs = self._filter_relevant_documents(
                    documents, intent_analysis, retrieval_strategy
                )
                
                # å¦‚æœè¿‡æ»¤åæ²¡æœ‰ç›¸å…³æ–‡æ¡£
                if not relevant_docs:
                    self.logger.warning(
                        f"æ£€ç´¢åˆ°{len(documents)}ä¸ªæ–‡æ¡£ï¼Œä½†éƒ½ä¸æŸ¥è¯¢æ„å›¾ä¸ç›¸å…³ã€‚"
                        f"æ£€æµ‹éƒ¨é—¨: {intent_analysis.detected_department}"
                    )
                    
                    # åˆ¤æ–­æ˜¯å¦æ˜¯æƒé™é—®é¢˜
                    if (intent_analysis.detected_department and 
                        retrieval_strategy and 
                        not retrieval_strategy.has_permission):
                        # ç”¨æˆ·æŸ¥è¯¢çš„æ˜¯æ— æƒé™éƒ¨é—¨çš„å†…å®¹ï¼Œä¸”å…¬å…±æ–‡ä»¶å¤¹æ²¡æœ‰ç›¸å…³æ–‡æ¡£
                        return self._generate_permission_denied_answer(
                            query, intent_analysis.detected_department, user_context
                        )
                    else:
                        # å…¶ä»–æƒ…å†µï¼šæ²¡æœ‰æ‰¾åˆ°ç›¸å…³æ–‡æ¡£
                        return self._generate_no_relevant_docs_answer(query, user_context)
                
                # ä½¿ç”¨è¿‡æ»¤åçš„ç›¸å…³æ–‡æ¡£
                documents = relevant_docs
            
            # åˆ¤æ–­å›ç­”ç±»å‹
            if documents:
                # åŸºäºæ–‡æ¡£çš„å›ç­”
                answer_data = self._generate_document_based_answer(
                    query, documents, user_context
                )
            else:
                # é€šç”¨çŸ¥è¯†å›ç­”
                answer_data = self._generate_general_knowledge_answer(
                    query, user_context
                )
            
            self.logger.info(f"å›ç­”ç”Ÿæˆå®Œæˆ: ç±»å‹={answer_data['answer_type']}")
            
            return answer_data
            
        except Exception as e:
            self.logger.error(f"å›ç­”ç”Ÿæˆå¤±è´¥: {str(e)}")
            
            # è¿”å›é”™è¯¯å›ç­”
            return self._generate_error_answer(str(e), user_context)
    
    def _generate_document_based_answer(
        self, 
        query: str, 
        documents: List[DocumentResult], 
        user_context: UserContext
    ) -> Dict[str, Any]:
        """ç”ŸæˆåŸºäºæ–‡æ¡£çš„å›ç­”"""
        # æ„å»ºæç¤ºè¯
        prompt = self.prompt_builder.build_document_based_prompt(
            query, documents, user_context
        )
        
        # è°ƒç”¨LLMç”Ÿæˆå›ç­”
        response = self.llm.invoke(prompt)
        answer = response.content.strip()
        
        # åå¤„ç†å›ç­”
        processed_answer = self._post_process_answer(answer, documents)
        
        return {
            "answer": processed_answer,
            "answer_type": "document_based",
            "source_documents": [
                {
                    "title": doc.title,
                    "department": doc.department,
                    "score": doc.score,
                    "document_id": doc.document_id
                }
                for doc in documents
            ],
            "confidence": self._calculate_confidence(documents),
            "source_info": "åŸºäºå…¬å¸æ–‡æ¡£"
        }
    
    def _generate_general_knowledge_answer(
        self, 
        query: str, 
        user_context: UserContext
    ) -> Dict[str, Any]:
        """ç”Ÿæˆé€šç”¨çŸ¥è¯†å›ç­”"""
        # æ„å»ºé€šç”¨çŸ¥è¯†æç¤ºè¯
        prompt = self.prompt_builder.build_general_knowledge_prompt(
            query, user_context
        )
        
        # è°ƒç”¨LLMç”Ÿæˆå›ç­”
        response = self.llm.invoke(prompt)
        answer = response.content.strip()
        
        # æ·»åŠ æ¥æºæ ‡è¯†
        if not answer.startswith("ğŸ’¡"):
            answer = "ğŸ’¡ **ä¿¡æ¯æ¥æºï¼šAIé€šç”¨çŸ¥è¯†ï¼ˆéå…¬å¸æ–‡æ¡£ï¼‰**\n\n" + answer
        
        # æ·»åŠ æ¸©é¦¨æç¤º
        if not "æ¸©é¦¨æç¤º" in answer:
            answer += "\n\nã€æ¸©é¦¨æç¤ºã€‘\næ­¤å›ç­”åŸºäºAIé€šç”¨çŸ¥è¯†ã€‚å¦‚éœ€äº†è§£å…¬å¸å…·ä½“æ”¿ç­–ï¼Œè¯·è”ç³»ç›¸å…³éƒ¨é—¨æˆ–æŸ¥é˜…å…¬å¸æ–‡æ¡£ã€‚"
        
        # æ·»åŠ å…è´£å£°æ˜
        disclaimer = "âš ï¸ å…è´£å£°æ˜ï¼šä»¥ä¸Šå›ç­”ç”±AIåŸºäºæ–‡æ¡£å†…å®¹åˆ†æç”Ÿæˆï¼Œä»…ä¾›å‚è€ƒã€‚å¦‚æœ‰ç–‘é—®æˆ–éœ€è¦å‡†ç¡®ä¿¡æ¯ï¼Œè¯·ä¸å…¬å¸ç›¸å…³éƒ¨é—¨è´Ÿè´£äººç¡®è®¤ã€‚"
        if disclaimer not in answer:
            answer += f"\n\n{disclaimer}"
        
        return {
            "answer": answer,
            "answer_type": "general_knowledge",
            "source_documents": [],
            "confidence": 0.6,  # é€šç”¨çŸ¥è¯†çš„é»˜è®¤ç½®ä¿¡åº¦
            "source_info": "AIé€šç”¨çŸ¥è¯†"
        }
    
    def _generate_template_answer(
        self, 
        query: str, 
        documents: List[DocumentResult], 
        user_context: UserContext
    ) -> Dict[str, Any]:
        """ç”Ÿæˆæ¨¡æ¿å›ç­”ï¼ˆLLMä¸å¯ç”¨æ—¶çš„é™çº§å¤„ç†ï¼‰"""
        if documents:
            # åŸºäºæ–‡æ¡£çš„æ¨¡æ¿å›ç­”
            doc_titles = [doc.title for doc in documents[:3]]
            answer = f"""ã€é—®é¢˜ç†è§£ã€‘
å…³äºã€Œ{query}ã€çš„æŸ¥è¯¢ï¼Œæˆ‘åœ¨å…¬å¸æ–‡æ¡£ä¸­æ‰¾åˆ°äº†ä»¥ä¸‹ç›¸å…³ä¿¡æ¯ï¼š

ã€ç›¸å…³æ–‡æ¡£ã€‘
{chr(10).join(f'â€¢ {title}' for title in doc_titles)}

ã€å»ºè®®æ“ä½œã€‘
1. è¯·æŸ¥é˜…ä¸Šè¿°ç›¸å…³æ–‡æ¡£è·å–è¯¦ç»†ä¿¡æ¯
2. å¦‚éœ€å…·ä½“æŒ‡å¯¼ï¼Œè¯·è”ç³»{user_context.department}éƒ¨é—¨
3. å¦‚æœ‰ç–‘é—®ï¼Œå¯å’¨è¯¢éƒ¨é—¨ç®¡ç†å‘˜

ã€æ³¨æ„äº‹é¡¹ã€‘
ä»¥ä¸Šä¿¡æ¯æ¥æºäºå…¬å¸å†…éƒ¨æ–‡æ¡£ï¼Œè¯·ä»¥æœ€æ–°ç‰ˆæœ¬ä¸ºå‡†ã€‚"""
        else:
            # é€šç”¨å›ç­”æ¨¡æ¿
            answer = f"""ğŸ’¡ **ä¿¡æ¯æ¥æºï¼šç³»ç»Ÿæç¤ºï¼ˆAIæœåŠ¡æš‚æ—¶ä¸å¯ç”¨ï¼‰**

å…³äºã€Œ{query}ã€çš„æŸ¥è¯¢ï¼Œç³»ç»Ÿæš‚æ—¶æ— æ³•æä¾›è¯¦ç»†å›ç­”ã€‚

ã€å»ºè®®æ“ä½œã€‘
1. è¯·è”ç³»{user_context.department}éƒ¨é—¨è·å–ç›¸å…³ä¿¡æ¯
2. æŸ¥é˜…å…¬å¸å†…éƒ¨æ–‡æ¡£æˆ–æ”¿ç­–æ‰‹å†Œ
3. å’¨è¯¢éƒ¨é—¨ç®¡ç†å‘˜æˆ–ç›¸å…³åŒäº‹

ã€æ¸©é¦¨æç¤ºã€‘
ç³»ç»Ÿæ­£åœ¨ç»´æŠ¤ä¸­ï¼Œè¯·ç¨åå†è¯•æˆ–é€šè¿‡å…¶ä»–æ–¹å¼è·å–å¸®åŠ©ã€‚"""
        
        # æ·»åŠ å…è´£å£°æ˜
        disclaimer = "âš ï¸ å…è´£å£°æ˜ï¼šä»¥ä¸Šå›ç­”ç”±AIåŸºäºæ–‡æ¡£å†…å®¹åˆ†æç”Ÿæˆï¼Œä»…ä¾›å‚è€ƒã€‚å¦‚æœ‰ç–‘é—®æˆ–éœ€è¦å‡†ç¡®ä¿¡æ¯ï¼Œè¯·ä¸å…¬å¸ç›¸å…³éƒ¨é—¨è´Ÿè´£äººç¡®è®¤ã€‚"
        answer += f"\n\n{disclaimer}"
        
        return {
            "answer": answer,
            "answer_type": "template",
            "source_documents": [],
            "confidence": 0.3,
            "source_info": "ç³»ç»Ÿæ¨¡æ¿"
        }
    
    def _generate_error_answer(self, error_msg: str, user_context: UserContext) -> Dict[str, Any]:
        """ç”Ÿæˆé”™è¯¯å›ç­”"""
        answer = f"""æŠ±æ­‰ï¼Œç³»ç»Ÿåœ¨å¤„ç†æ‚¨çš„æŸ¥è¯¢æ—¶é‡åˆ°äº†é—®é¢˜ã€‚

ã€é”™è¯¯ä¿¡æ¯ã€‘
{error_msg}

ã€å»ºè®®æ“ä½œã€‘
1. è¯·ç¨åé‡è¯•
2. è”ç³»{user_context.department}éƒ¨é—¨è·å–å¸®åŠ©
3. å¦‚é—®é¢˜æŒç»­ï¼Œè¯·è”ç³»æŠ€æœ¯æ”¯æŒ

ã€è”ç³»æ–¹å¼ã€‘
å¦‚éœ€ç´§æ€¥å¸®åŠ©ï¼Œè¯·ç›´æ¥è”ç³»ç›¸å…³éƒ¨é—¨æˆ–ç³»ç»Ÿç®¡ç†å‘˜ã€‚"""
        
        # æ·»åŠ å…è´£å£°æ˜
        disclaimer = "âš ï¸ å…è´£å£°æ˜ï¼šä»¥ä¸Šå›ç­”ç”±AIåŸºäºæ–‡æ¡£å†…å®¹åˆ†æç”Ÿæˆï¼Œä»…ä¾›å‚è€ƒã€‚å¦‚æœ‰ç–‘é—®æˆ–éœ€è¦å‡†ç¡®ä¿¡æ¯ï¼Œè¯·ä¸å…¬å¸ç›¸å…³éƒ¨é—¨è´Ÿè´£äººç¡®è®¤ã€‚"
        answer += f"\n\n{disclaimer}"
        
        return {
            "answer": answer,
            "answer_type": "error",
            "source_documents": [],
            "confidence": 0.0,
            "source_info": "ç³»ç»Ÿé”™è¯¯"
        }
    
    def _filter_relevant_documents(
        self,
        documents: List[DocumentResult],
        intent_analysis,
        retrieval_strategy
    ) -> List[DocumentResult]:
        """è¿‡æ»¤ç›¸å…³æ–‡æ¡£
        
        æ£€æŸ¥æ–‡æ¡£æ˜¯å¦ä¸æŸ¥è¯¢æ„å›¾åŒ¹é…ï¼š
        1. å¦‚æœç”¨æˆ·æŸ¥è¯¢ç‰¹å®šéƒ¨é—¨çš„å†…å®¹ï¼Œæ£€æŸ¥æ–‡æ¡£æ˜¯å¦æ¥è‡ªè¯¥éƒ¨é—¨æˆ–ç›¸å…³
        2. ä½¿ç”¨æ–‡æ¡£æ ‡é¢˜å’Œéƒ¨é—¨ä¿¡æ¯è¿›è¡ŒåŒ¹é…
        """
        if not intent_analysis or not intent_analysis.detected_department:
            # æ²¡æœ‰æ£€æµ‹åˆ°ç‰¹å®šéƒ¨é—¨ï¼Œè¿”å›æ‰€æœ‰æ–‡æ¡£
            return documents
        
        detected_dept = intent_analysis.detected_department
        keywords = intent_analysis.keywords
        
        self.logger.info(
            f"è¿‡æ»¤æ–‡æ¡£ç›¸å…³æ€§: æ£€æµ‹éƒ¨é—¨={detected_dept}, "
            f"å…³é”®è¯={keywords}, æ–‡æ¡£æ•°={len(documents)}"
        )
        
        relevant_docs = []
        for doc in documents:
            # æ£€æŸ¥1ï¼šæ–‡æ¡£éƒ¨é—¨æ˜¯å¦åŒ¹é…
            if doc.department == detected_dept:
                relevant_docs.append(doc)
                self.logger.debug(f"âœ“ æ–‡æ¡£ç›¸å…³ï¼ˆéƒ¨é—¨åŒ¹é…ï¼‰: {doc.title} ({doc.department})")
                continue
            
            # æ£€æŸ¥2ï¼šæ–‡æ¡£æ ‡é¢˜æ˜¯å¦åŒ…å«æ£€æµ‹åˆ°çš„éƒ¨é—¨åç§°
            if detected_dept in doc.title:
                relevant_docs.append(doc)
                self.logger.debug(f"âœ“ æ–‡æ¡£ç›¸å…³ï¼ˆæ ‡é¢˜åŒ…å«éƒ¨é—¨ï¼‰: {doc.title}")
                continue
            
            # æ£€æŸ¥3ï¼šæ–‡æ¡£æ ‡é¢˜æ˜¯å¦åŒ…å«æŸ¥è¯¢å…³é”®è¯
            if keywords:
                title_lower = doc.title.lower()
                if any(keyword.lower() in title_lower for keyword in keywords):
                    relevant_docs.append(doc)
                    self.logger.debug(f"âœ“ æ–‡æ¡£ç›¸å…³ï¼ˆæ ‡é¢˜åŒ…å«å…³é”®è¯ï¼‰: {doc.title}")
                    continue
            
            # æ–‡æ¡£ä¸ç›¸å…³
            self.logger.debug(
                f"âœ— æ–‡æ¡£ä¸ç›¸å…³: {doc.title} (éƒ¨é—¨: {doc.department}, "
                f"æ£€æµ‹éƒ¨é—¨: {detected_dept})"
            )
        
        self.logger.info(
            f"æ–‡æ¡£ç›¸å…³æ€§è¿‡æ»¤å®Œæˆ: {len(documents)} -> {len(relevant_docs)}"
        )
        
        return relevant_docs
    
    def _generate_permission_denied_answer(
        self,
        query: str,
        detected_department: str,
        user_context: UserContext
    ) -> Dict[str, Any]:
        """ç”Ÿæˆæƒé™æ‹’ç»å›ç­”"""
        answer = f"""ã€æƒé™æç¤ºã€‘

æ‚¨æŸ¥è¯¢çš„å†…å®¹æ¶‰åŠã€Œ{detected_department}ã€éƒ¨é—¨ï¼Œä½†æ‚¨å½“å‰æ— æƒè®¿é—®è¯¥éƒ¨é—¨çš„æ–‡æ¡£ã€‚

ã€æ‚¨çš„æƒé™ã€‘
- å½“å‰éƒ¨é—¨ï¼š{user_context.department}
- å¯è®¿é—®éƒ¨é—¨ï¼š{', '.join(user_context.accessible_folders)}

ã€å»ºè®®æ“ä½œã€‘
1. å¦‚éœ€æŸ¥çœ‹{detected_department}éƒ¨é—¨çš„æ–‡æ¡£ï¼Œè¯·è”ç³»{detected_department}éƒ¨é—¨è´Ÿè´£äººç”³è¯·æƒé™
2. æ‚¨å¯ä»¥åœ¨å…¬å…±æ–‡ä»¶å¤¹ä¸­æŸ¥æ‰¾ç›¸å…³ä¿¡æ¯
3. è”ç³»ç³»ç»Ÿç®¡ç†å‘˜äº†è§£æƒé™ç”³è¯·æµç¨‹

ã€æ¸©é¦¨æç¤ºã€‘
å…¬å¸æ–‡æ¡£æŒ‰éƒ¨é—¨è¿›è¡Œæƒé™ç®¡ç†ï¼Œä»¥ä¿æŠ¤æ•æ„Ÿä¿¡æ¯ã€‚å¦‚æœ‰ä¸šåŠ¡éœ€è¦ï¼Œè¯·é€šè¿‡æ­£è§„æµç¨‹ç”³è¯·è®¿é—®æƒé™ã€‚"""
        
        # æ·»åŠ å…è´£å£°æ˜
        disclaimer = "âš ï¸ å…è´£å£°æ˜ï¼šä»¥ä¸Šå›ç­”ç”±AIåŸºäºæ–‡æ¡£å†…å®¹åˆ†æç”Ÿæˆï¼Œä»…ä¾›å‚è€ƒã€‚å¦‚æœ‰ç–‘é—®æˆ–éœ€è¦å‡†ç¡®ä¿¡æ¯ï¼Œè¯·ä¸å…¬å¸ç›¸å…³éƒ¨é—¨è´Ÿè´£äººç¡®è®¤ã€‚"
        answer += f"\n\n{disclaimer}"
        
        return {
            "answer": answer,
            "answer_type": "permission_denied",
            "source_documents": [],
            "confidence": 1.0,  # æƒé™åˆ¤æ–­æ˜¯ç¡®å®šçš„
            "source_info": "æƒé™æ§åˆ¶"
        }
    
    def _generate_no_relevant_docs_answer(
        self,
        query: str,
        user_context: UserContext
    ) -> Dict[str, Any]:
        """ç”Ÿæˆæœªæ‰¾åˆ°ç›¸å…³æ–‡æ¡£çš„å›ç­”"""
        answer = f"""ã€æŸ¥è¯¢ç»“æœã€‘

æŠ±æ­‰ï¼Œæœªèƒ½åœ¨æ‚¨æœ‰æƒè®¿é—®çš„æ–‡æ¡£ä¸­æ‰¾åˆ°ä¸ã€Œ{query}ã€ç›¸å…³çš„å†…å®¹ã€‚

ã€æ‚¨çš„æƒé™èŒƒå›´ã€‘
- å½“å‰éƒ¨é—¨ï¼š{user_context.department}
- å¯è®¿é—®éƒ¨é—¨ï¼š{', '.join(user_context.accessible_folders)}

ã€å»ºè®®æ“ä½œã€‘
1. å°è¯•ä½¿ç”¨ä¸åŒçš„å…³é”®è¯é‡æ–°æŸ¥è¯¢
2. æ£€æŸ¥æŸ¥è¯¢å†…å®¹æ˜¯å¦å±äºæ‚¨æœ‰æƒè®¿é—®çš„éƒ¨é—¨èŒƒå›´
3. è”ç³»{user_context.department}éƒ¨é—¨åŒäº‹æˆ–ç®¡ç†å‘˜è·å–å¸®åŠ©
4. å¦‚éœ€è®¿é—®å…¶ä»–éƒ¨é—¨çš„æ–‡æ¡£ï¼Œè¯·ç”³è¯·ç›¸åº”æƒé™

ã€æ¸©é¦¨æç¤ºã€‘
å¦‚æœæ‚¨ç¡®å®šç›¸å…³æ–‡æ¡£åº”è¯¥å­˜åœ¨ï¼Œå¯èƒ½æ˜¯ï¼š
- æ–‡æ¡£å°šæœªä¸Šä¼ åˆ°ç³»ç»Ÿ
- æ–‡æ¡£çš„å…³é”®è¯ä¸æ‚¨çš„æŸ¥è¯¢ä¸åŒ¹é…
- æ–‡æ¡£å­˜å‚¨åœ¨æ‚¨æ— æƒè®¿é—®çš„éƒ¨é—¨ä¸­"""
        
        # æ·»åŠ å…è´£å£°æ˜
        disclaimer = "âš ï¸ å…è´£å£°æ˜ï¼šä»¥ä¸Šå›ç­”ç”±AIåŸºäºæ–‡æ¡£å†…å®¹åˆ†æç”Ÿæˆï¼Œä»…ä¾›å‚è€ƒã€‚å¦‚æœ‰ç–‘é—®æˆ–éœ€è¦å‡†ç¡®ä¿¡æ¯ï¼Œè¯·ä¸å…¬å¸ç›¸å…³éƒ¨é—¨è´Ÿè´£äººç¡®è®¤ã€‚"
        answer += f"\n\n{disclaimer}"
        
        return {
            "answer": answer,
            "answer_type": "no_relevant_docs",
            "source_documents": [],
            "confidence": 0.8,  # æœªæ‰¾åˆ°æ–‡æ¡£æ˜¯ç¡®å®šçš„
            "source_info": "æœªæ‰¾åˆ°ç›¸å…³æ–‡æ¡£"
        }
    
    def _post_process_answer(self, answer: str, documents: List[DocumentResult]) -> str:
        """åå¤„ç†å›ç­”"""
        # ç¡®ä¿å›ç­”åŒ…å«æ–‡æ¡£ä¾æ®éƒ¨åˆ†
        if "ã€æ–‡æ¡£ä¾æ®ã€‘" not in answer and documents:
            doc_list = "\n".join(f"â€¢ {doc.title}" for doc in documents[:3])
            answer = f"ã€æ–‡æ¡£ä¾æ®ã€‘\n{doc_list}\n\n{answer}"
        
        # æ·»åŠ å‚è€ƒæ–‡æ¡£åˆ—è¡¨
        if documents and "ğŸ“Œ å‚è€ƒæ–‡æ¡£" not in answer:
            ref_docs = "\n".join(
                f"â€¢ {doc.title} ({doc.department})"
                for doc in documents[:5]
            )
            answer += f"\n\nğŸ“Œ å‚è€ƒæ–‡æ¡£\n{ref_docs}"
        
        # æ·»åŠ å…è´£å£°æ˜ï¼ˆå¦‚æœè¿˜æ²¡æœ‰ï¼‰
        disclaimer = "âš ï¸ å…è´£å£°æ˜ï¼šä»¥ä¸Šå›ç­”ç”±AIåŸºäºæ–‡æ¡£å†…å®¹åˆ†æç”Ÿæˆï¼Œä»…ä¾›å‚è€ƒã€‚å¦‚æœ‰ç–‘é—®æˆ–éœ€è¦å‡†ç¡®ä¿¡æ¯ï¼Œè¯·ä¸å…¬å¸ç›¸å…³éƒ¨é—¨è´Ÿè´£äººç¡®è®¤ã€‚"
        if disclaimer not in answer:
            answer += f"\n\n{disclaimer}"
        
        return answer
    
    def _calculate_confidence(self, documents: List[DocumentResult]) -> float:
        """è®¡ç®—å›ç­”ç½®ä¿¡åº¦"""
        if not documents:
            return 0.0
        
        # åŸºäºæ–‡æ¡£æ•°é‡å’Œç›¸å…³æ€§åˆ†æ•°è®¡ç®—ç½®ä¿¡åº¦
        avg_score = sum(doc.score for doc in documents) / len(documents)
        doc_count_factor = min(len(documents) / 5.0, 1.0)  # æ–‡æ¡£æ•°é‡å› å­
        
        confidence = (avg_score * 0.7 + doc_count_factor * 0.3)
        return round(confidence, 3)
    
    def _validate_inputs(self, inputs: Dict[str, Any]) -> None:
        """éªŒè¯è¾“å…¥æ•°æ®"""
        super()._validate_inputs(inputs)
        
        if "user_context" not in inputs:
            raise ValueError("ç¼ºå°‘ç”¨æˆ·ä¸Šä¸‹æ–‡ä¿¡æ¯")


class PromptBuilder:
    """æç¤ºè¯æ„å»ºå™¨"""
    
    def build_document_based_prompt(
        self, 
        query: str, 
        documents: List[DocumentResult], 
        user_context: UserContext
    ) -> str:
        """æ„å»ºåŸºäºæ–‡æ¡£çš„æç¤ºè¯"""
        # æ ¼å¼åŒ–æ–‡æ¡£å†…å®¹
        formatted_docs = self._format_documents(documents)
        
        # è·å–è§’è‰²ç‰¹å®šæŒ‡ä»¤
        role_instructions = self._get_role_instructions(user_context.role)
        
        prompt = f"""ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„ä¼ä¸šçŸ¥è¯†åº“åŠ©æ‰‹ã€‚è¯·åŸºäºæä¾›çš„å…¬å¸æ–‡æ¡£å›ç­”ç”¨æˆ·é—®é¢˜ã€‚

ç”¨æˆ·ä¿¡æ¯ï¼š
- å§“åï¼š{user_context.username}
- éƒ¨é—¨ï¼š{user_context.department}
- è§’è‰²ï¼š{user_context.role}
- å¯è®¿é—®éƒ¨é—¨ï¼š{', '.join(user_context.accessible_folders)}

è§’è‰²è¦æ±‚ï¼š{role_instructions}

ç”¨æˆ·é—®é¢˜ï¼š{query}

ç›¸å…³æ–‡æ¡£ï¼š
{formatted_docs}

å›ç­”è¦æ±‚ï¼š
1. ä¸¥æ ¼åŸºäºæä¾›çš„æ–‡æ¡£å†…å®¹å›ç­”
2. åœ¨å›ç­”å¼€å¤´æ·»åŠ ã€æ–‡æ¡£ä¾æ®ã€‘éƒ¨åˆ†ï¼Œåˆ—å‡ºå¼•ç”¨çš„æ–‡æ¡£
3. æä¾›è¯¦ç»†çš„æ“ä½œæ­¥éª¤å’Œæ³¨æ„äº‹é¡¹
4. å¦‚æœæ–‡æ¡£ä¿¡æ¯ä¸å®Œæ•´ï¼Œæ˜ç¡®è¯´æ˜ç¼ºå¤±çš„å†…å®¹
5. åœ¨å›ç­”æœ«å°¾æ·»åŠ "ğŸ“Œ å‚è€ƒæ–‡æ¡£"åˆ—è¡¨
6. åœ¨å›ç­”æœ€åå¿…é¡»æ·»åŠ å…è´£å£°æ˜ï¼š"âš ï¸ å…è´£å£°æ˜ï¼šä»¥ä¸Šå›ç­”ç”±AIåŸºäºæ–‡æ¡£å†…å®¹åˆ†æç”Ÿæˆï¼Œä»…ä¾›å‚è€ƒã€‚å¦‚æœ‰ç–‘é—®æˆ–éœ€è¦å‡†ç¡®ä¿¡æ¯ï¼Œè¯·ä¸å…¬å¸ç›¸å…³éƒ¨é—¨è´Ÿè´£äººç¡®è®¤ã€‚"
7. ä¿æŒä¸“ä¸šã€å‡†ç¡®ã€æœ‰å¸®åŠ©çš„è¯­è°ƒ

è¯·å¼€å§‹å›ç­”ï¼š"""
        
        return prompt
    
    def build_general_knowledge_prompt(
        self, 
        query: str, 
        user_context: UserContext
    ) -> str:
        """æ„å»ºé€šç”¨çŸ¥è¯†æç¤ºè¯"""
        role_instructions = self._get_role_instructions(user_context.role)
        
        prompt = f"""ä½ æ˜¯ä¸€ä¸ªå‹å¥½ã€ä¸“ä¸šçš„AIåŠ©æ‰‹ã€‚

ç”¨æˆ·ä¿¡æ¯ï¼š
- éƒ¨é—¨ï¼š{user_context.department}
- è§’è‰²ï¼š{user_context.role}

è§’è‰²è¦æ±‚ï¼š{role_instructions}

ç”¨æˆ·é—®é¢˜ï¼š{query}

å½“å‰æƒ…å†µï¼šçŸ¥è¯†åº“ä¸­æ²¡æœ‰æ‰¾åˆ°ç›¸å…³çš„å…¬å¸æ–‡æ¡£ã€‚

è¯·ç›´æ¥å›ç­”ç”¨æˆ·çš„é—®é¢˜ã€‚å¦‚æœæ˜¯ç®€å•çš„å¸¸è¯†é—®é¢˜ï¼Œè¯·ç®€æ´æ˜äº†åœ°å›ç­”ã€‚
å¦‚æœæ˜¯å¤æ‚çš„ä¸“ä¸šé—®é¢˜ï¼Œè¯·æä¾›æœ‰å¸®åŠ©çš„å»ºè®®ã€‚

é‡è¦æç¤ºï¼š
1. è¯·åœ¨å›ç­”å¼€å¤´æ·»åŠ "ğŸ’¡ **ä¿¡æ¯æ¥æºï¼šAIé€šç”¨çŸ¥è¯†ï¼ˆéå…¬å¸æ–‡æ¡£ï¼‰**"
2. ç›´æ¥å›ç­”é—®é¢˜ï¼Œä¿æŒå‹å¥½ã€è‡ªç„¶çš„è¯­æ°”
3. åœ¨å›ç­”æœ«å°¾æ·»åŠ æ¸©é¦¨æç¤ºï¼Œè¯´æ˜è¿™æ˜¯åŸºäºAIé€šç”¨çŸ¥è¯†çš„å›ç­”

è¯·å¼€å§‹å›ç­”ï¼š"""
        
        return prompt
    
    def _format_documents(self, documents: List[DocumentResult]) -> str:
        """æ ¼å¼åŒ–æ–‡æ¡£å†…å®¹"""
        if not documents:
            return "æœªæ‰¾åˆ°ç›¸å…³æ–‡æ¡£ã€‚"
        
        formatted_docs = []
        for i, doc in enumerate(documents, 1):
            formatted_doc = f"""
ã€æ–‡æ¡£{i}ã€‘{doc.title} ({doc.department})
ç›¸å…³æ€§ï¼š{doc.score:.2f}
å†…å®¹ï¼š{doc.content[:500]}{'...' if len(doc.content) > 500 else ''}
"""
            formatted_docs.append(formatted_doc)
        
        return "\n".join(formatted_docs)
    
    def _get_role_instructions(self, user_role) -> str:
        """è·å–è§’è‰²ç‰¹å®šæŒ‡ä»¤"""
        from .models import UserRole
        
        role_instructions = {
            UserRole.EMPLOYEE: "ä½œä¸ºå‘˜å·¥ï¼Œè¯·æä¾›æ˜“æ‡‚çš„æ”¿ç­–è§£é‡Šå’Œæ“ä½œæŒ‡å¯¼",
            UserRole.ADMIN: "ä½œä¸ºéƒ¨é—¨ç®¡ç†å‘˜ï¼Œè¯·æä¾›è¯¦ç»†çš„ç®¡ç†æŒ‡å¯¼å’Œæ“ä½œæ­¥éª¤",
            UserRole.SUPER_ADMIN: "ä½œä¸ºè¶…çº§ç®¡ç†å‘˜ï¼Œè¯·æä¾›å…¨é¢çš„ç³»ç»Ÿåˆ†æå’Œæˆ˜ç•¥å»ºè®®"
        }
        
        return role_instructions.get(user_role, "è¯·æä¾›ä¸“ä¸šçš„æŒ‡å¯¼")


class AnswerQualityEvaluator:
    """å›ç­”è´¨é‡è¯„ä¼°å™¨"""
    
    @staticmethod
    def evaluate_answer(answer: str, documents: List[DocumentResult], query: str) -> Dict[str, Any]:
        """è¯„ä¼°å›ç­”è´¨é‡"""
        metrics = {
            "completeness": AnswerQualityEvaluator._evaluate_completeness(answer, query),
            "accuracy": AnswerQualityEvaluator._evaluate_accuracy(answer, documents),
            "clarity": AnswerQualityEvaluator._evaluate_clarity(answer),
            "helpfulness": AnswerQualityEvaluator._evaluate_helpfulness(answer)
        }
        
        # è®¡ç®—æ€»ä½“è´¨é‡åˆ†æ•°
        overall_score = sum(metrics.values()) / len(metrics)
        
        return {
            "overall_score": overall_score,
            "metrics": metrics,
            "quality_level": AnswerQualityEvaluator._get_quality_level(overall_score)
        }
    
    @staticmethod
    def _evaluate_completeness(answer: str, query: str) -> float:
        """è¯„ä¼°å›ç­”å®Œæ•´æ€§"""
        # ç®€å•çš„å®Œæ•´æ€§è¯„ä¼°
        if len(answer) < 50:
            return 0.3
        elif len(answer) < 200:
            return 0.6
        else:
            return 0.9
    
    @staticmethod
    def _evaluate_accuracy(answer: str, documents: List[DocumentResult]) -> float:
        """è¯„ä¼°å›ç­”å‡†ç¡®æ€§"""
        if not documents:
            return 0.5  # é€šç”¨çŸ¥è¯†å›ç­”çš„é»˜è®¤å‡†ç¡®æ€§
        
        # æ£€æŸ¥æ˜¯å¦åŒ…å«æ–‡æ¡£ä¾æ®
        if "ã€æ–‡æ¡£ä¾æ®ã€‘" in answer:
            return 0.9
        elif "å‚è€ƒæ–‡æ¡£" in answer:
            return 0.7
        else:
            return 0.5
    
    @staticmethod
    def _evaluate_clarity(answer: str) -> float:
        """è¯„ä¼°å›ç­”æ¸…æ™°åº¦"""
        # æ£€æŸ¥ç»“æ„åŒ–å…ƒç´ 
        structure_indicators = ["ã€", "ã€‘", "â€¢", "1.", "2.", "3."]
        structure_score = sum(1 for indicator in structure_indicators if indicator in answer)
        
        return min(structure_score / 5.0, 1.0)
    
    @staticmethod
    def _evaluate_helpfulness(answer: str) -> float:
        """è¯„ä¼°å›ç­”æœ‰ç”¨æ€§"""
        helpful_indicators = ["å»ºè®®", "æ“ä½œ", "æ­¥éª¤", "æ³¨æ„", "è”ç³»", "æŸ¥é˜…"]
        helpful_score = sum(1 for indicator in helpful_indicators if indicator in answer)
        
        return min(helpful_score / 4.0, 1.0)
    
    @staticmethod
    def _get_quality_level(score: float) -> str:
        """è·å–è´¨é‡ç­‰çº§"""
        if score >= 0.8:
            return "excellent"
        elif score >= 0.6:
            return "good"
        elif score >= 0.4:
            return "fair"
        else:
            return "poor"